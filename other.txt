import os
import gradio as gr
import whisper
from gtts import gTTS
from groq import Groq
from pydub import AudioSegment

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# Initialize the Groq client
api_key = os.environ.get('GROQ_API_KEY')
client = Groq(api_key=api_key)

# Test Groq connection
try:
    client.models.list()
    print("================================ Groq Connection Successful================================")
except Exception as e:
    print("================================ Groq Connection Failed================================")
    print("Error: ", e)

# Initialize Whisper model
model = whisper.load_model("tiny", download_root="~/.cache/whisper")
print("================================ Whisper Model Loaded================================")

# Define Domain Restriction Logic
DOMAIN = 'legal issues'
DEFAULT_RESPONSE = 'This is out of my knowledge. Please try with related questions to legal issues.'


def is_relevant(question):
    legal_keywords = ['law', 'legal', 'court', 'contract', 'rights']
    return any(keyword in question.lower() for keyword in legal_keywords)


def text_to_speech(text):
    tts = gTTS(text=text, lang='en')
    audio_file = 'output.mp3'
    tts.save(audio_file)
    return audio_file


def process_input(text, audio):
    if audio is not None:
        audio_file = audio  # Use the audio filepath directly
        result = model.transcribe(audio_file)
        question = result['text']
    elif text:
        question = text
    else:
        return 'Please provide text or audio input.', None

    print("================================ Question Transcribed================================")
    print(question)
    print("================================ Question Transcribed================================")

    if is_relevant(question):
        response = generate_response(question)
    else:
        response = DEFAULT_RESPONSE

    print("================================ Response Generated================================")
    print(response)
    print("================================ Response Generated================================")

    audio_output = text_to_speech(response)
    return response, audio_output


def generate_response(question):
    system_prompt = {
        "role": "system",
        "content": f"You are an expert in {DOMAIN}. Provide concise answers with maximum 150 characters to questions "
                   f"related to {DOMAIN}."
    }
    chat_history = [system_prompt, {"role": "user", "content": question}]

    try:
        response = client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=chat_history,
            max_tokens=150,
            temperature=0.7
        )
        assistant_reply = response.choices[0].message.content
        return assistant_reply
    except Exception as e:
        print("================================ Groq Connection Failed================================")
        print("Error: ", e)
        return "I'm sorry, but I'm unable to provide a response at this time."


# Build the Gradio Interface
inputs = [
    gr.Textbox(lines=2, label="Type your question here..."),
    gr.Audio(sources=["microphone", "upload"], type="filepath", label="Audio Input")
]

outputs = [
    gr.Textbox(label="Chatbot Response"),
    gr.Audio(label="Assistant's Response", type="filepath")
]

interface = gr.Interface(
    fn=process_input,
    inputs=inputs,
    outputs=outputs,
    title="Domain-Specific Q&A Chatbot",
    description="Ask questions related to legal issues."
)


def main():
    interface.launch()


if __name__ == "__main__":
    main()
